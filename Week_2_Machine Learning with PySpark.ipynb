{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 4\n\n# Remove the 'flight' column\nflights_drop_column = flights.drop('flight')\n\n# Number of records with missing 'delay' values\nflights_drop_column.filter('delay IS NULL').count()\n\n# Remove records with missing 'delay' values\nflights_valid_delay = flights_drop_column.filter('delay IS NOT NULL')\n\n# Remove records with missing values in any column and get the number of remaining rows\nflights_none_missing = flights_valid_delay.dropna()\nprint(flights_none_missing.count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 5\n\n# Import the required function\nfrom pyspark.sql.functions import ____\n\n# Convert 'mile' to 'km' and drop 'mile' column\nflights_km = flights.____('km', ____(____ * ____, 0)) \\\n                    .____('mile')\n\n# Create 'label' column indicating whether flight delayed (1) or not (0)\nflights_km = flights_km.____('label', (____).cast('integer'))\n\n# Check first five records\nflights_km.show(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 6\n\nfrom pyspark.ml.feature import ____\n\n# Create an indexer\nindexer = ____(inputCol=____, outputCol='carrier_idx')\n\n# Indexer identifies categories in the data\nindexer_model = indexer.____(flights)\n\n# Indexer creates a new column with numeric index values\nflights_indexed = ____.____(____)\n\n# Repeat the process for the other categorical feature\nflights_indexed = ____(inputCol=____, outputCol='org_idx').____(____).____(____)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 7\n\n# Import the necessary class\nfrom pyspark.ml.feature import VectorAssembler\n\n# Create an assembler object\nassembler = VectorAssembler(inputCols=[\n    'mon','dom','dow','carrier_idx','org_idx','km','depart','duration'\n], outputCol='features')\n\n# Consolidate predictor columns\nflights_assembled = assembler.transform(flights)\n\n# Check the resulting column\nflights_assembled.select('features', 'delay').show(5, truncate=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 8\n\n# Split into training and testing sets in a 80:20 ratio\nflights_train, flights_test = flights.randomSplit([0.8,0.2], seed=17)\n\n# Check that training set has around 80% of records\ntraining_ratio = flights_train.count() / flights.count()\nprint(training_ratio)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 9\n\n# Import the Decision Tree Classifier class\nfrom pyspark.ml.classification import DecisionTreeClassifier\n\n# Create a classifier object and fit to the training data\ntree = DecisionTreeClassifier()\ntree_model = tree.fit(flights_train)\n\n# Create predictions for the testing data and take a look at the predictions\nprediction = tree_model.transform(flights_test)\nprediction.select('label', 'prediction', 'probability').show(5, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 10\n\n# Create a confusion matrix\nprediction.groupBy('label', 'prediction').count().show()\n\n# Calculate the elements of the confusion matrix\nTN = prediction.filter('prediction = 0 AND label = prediction').count()\nTP = prediction.filter('prediction = 1 AND label = prediction').count()\nFN = prediction.filter('prediction = 0 AND label = 1').count()\nFP = prediction.filter('prediction = 1 AND label = 0').count()\n\n# Accuracy measures the proportion of correct predictions\naccuracy = (TN+TP)/(TN+TP+FN+FP)\nprint(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 11\n\n# Import the logistic regression class\nfrom pyspark.ml.classification import LogisticRegression\n\n# Create a classifier object and train on training data\nlogistic = LogisticRegression().fit(flights_train)\n\n# Create predictions for the testing data and show confusion matrix\nprediction = logistic.transform(flights_test)\nprediction.groupBy('label','prediction').count().show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 12\n\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n\n# Calculate precision and recall\nprecision = TP/(TP+FP)\nrecall = TP/(TP+FN)\nprint('precision = {:.2f}\\nrecall    = {:.2f}'.format(precision, recall))\n\n# Find weighted precision\nmulti_evaluator = MulticlassClassificationEvaluator()\nweighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n\n# Find AUC\nbinary_evaluator = BinaryClassificationEvaluator()\nauc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: \"areaUnderROC\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 13\n\n# Import the necessary functions\nfrom pyspark.sql.functions import regexp_replace\nfrom pyspark.ml.feature import Tokenizer\n\n# Remove punctuation (REGEX provided) and numbers\nwrangled = sms.withColumn('text', regexp_replace(sms.text, '[_():;,.!?\\\\-]', ' '))\nwrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n\n# Merge multiple spaces\nwrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n\n# Split the text into words\nwrangled = Tokenizer(inputCol='text', outputCol='words').transform(wrangled)\n\nwrangled.show(4, truncate=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 14\n\nfrom pyspark.ml.feature import StopWordsRemover, HashingTF, IDF\n\n# Remove stop words.\nwrangled = StopWordsRemover(inputCol='words', outputCol='terms')\\\n      .transform(sms)\n\n# Apply the hashing trick\nwrangled = HashingTF(inputCol='terms', outputCol='hash', numFeatures=1024)\\\n      .transform(wrangled)\n\n# Convert hashed symbols to TF-IDF\ntf_idf = IDF(inputCol='hash', outputCol='features')\\\n      .fit(wrangled).transform(wrangled)\n      \ntf_idf.select('terms', 'features').show(4, truncate=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 15\n\n# Split the data into training and testing sets\nsms_train, sms_test = sms.randomSplit([0.8,0.2], seed=13)\n\n# Fit a Logistic Regression model to the training data\nlogistic = LogisticRegression(regParam=0.2).fit(sms_train)\n\n# Make predictions on the testing data\nprediction = logistic.transform(sms_test)\n\n# Create a confusion matrix, comparing predictions to known labels\nprediction.groupBy('label','prediction').count().show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}